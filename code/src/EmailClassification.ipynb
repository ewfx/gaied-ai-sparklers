{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f172548d"
      },
      "source": [
        "\n",
        "# üì© AI-Powered Orchestrator for Email Classification & Triage Routing\n",
        "\n",
        "## üìå Problem Statement\n",
        "Commercial banks receive a high volume of service requests via email daily. These emails contain diverse requests with attachments, requiring manual classification, metadata extraction, and routing to appropriate teams. This manual process is:\n",
        "- **Time-consuming and error-prone.**\n",
        "- **Costly in terms of human effort.**\n",
        "- **Challenging due to complex email formats and nested attachments.**\n",
        "\n",
        "## ‚úÖ Solution Overview\n",
        "To automate email classification and metadata extraction, this system follows these key steps:\n",
        "\n",
        "1Ô∏è‚É£ **Email Content Extraction** - Reads emails, extracts text, and processes attachments (PDF, DOCX, Images, Nested EML).  \n",
        "2Ô∏è‚É£ **Duplicate Email Detection** - Uses **ChromaDB** & **sentence-transformers** to identify and filter duplicate emails.  \n",
        "3Ô∏è‚É£ **Email Classification** - Uses **GPT-3.5-turbo** to determine request type & sub-request type.  \n",
        "4Ô∏è‚É£ **Metadata Extraction** - Uses **GPT-4-turbo** to extract structured metadata fields from emails.  \n",
        "5Ô∏è‚É£ **Gradio UI for Display** - A user-friendly interface to upload emails and review extracted classifications.  \n",
        "\n",
        "---\n",
        "\n",
        "### üîß **Tech Stack Used:**\n",
        "‚úÖ **OpenAI GPT Models**: `gpt-3.5-turbo`, `gpt-4-turbo`  \n",
        "‚úÖ **Vector Database**: `ChromaDB` for duplicate detection  \n",
        "‚úÖ **Embeddings & NLP**: `sentence-transformers` (`all-MiniLM-L6-v2`)  \n",
        "‚úÖ **Document Processing**: `pdfplumber`, `python-docx`, `easyocr`  \n",
        "‚úÖ **Web UI**: `Gradio` for interactive visualization  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmx39wLmoCDv"
      },
      "source": [
        "# Email & document classification for triage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbKQ2z9ioFOw"
      },
      "source": [
        "## Email Classification\n",
        "- Uses GPT to classify emails into Request Type and Sub Request Type.\n",
        "- Returns a confidence score for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXnqf2F2prT0",
        "outputId": "a393a301-a95f-4b75-9332-58703f41cf9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.4)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.48)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.6.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.7)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.11.1.4)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.12)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.21.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-cache-dir openai langchain langchain_openai pdfplumber pdf2image easyocr python-docx fpdf pymupdf chromadb sentence-transformers gradio pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxnQZk05SrOr"
      },
      "source": [
        "## Import the Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jrnIP_FWOjgE"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import openai\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "import email\n",
        "import fitz  # PyMuPDF for PDFs\n",
        "import docx\n",
        "import pdfplumber\n",
        "from pdfminer.pdfparser import PDFSyntaxError\n",
        "import mimetypes\n",
        "from email import policy\n",
        "from email.parser import BytesParser\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import uuid\n",
        "import base64\n",
        "\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHRgmbKnXC89"
      },
      "source": [
        "## Mount the google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3TDNW2tXDdw",
        "outputId": "e0f6ef9b-9e1e-4a72-e269-2eab7d7c40b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqJZi82cXYuM"
      },
      "source": [
        "## Setup the Api Key for using Open Api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zpsC8b7oXXWS"
      },
      "outputs": [],
      "source": [
        "# Set the API key\n",
        "folder_path = \"/content/drive/MyDrive/EmailClassification/\"\n",
        "\n",
        "# Read the text file containing the API key\n",
        "with open(folder_path + 'OpenAI_API_Key.txt', 'r') as f:\n",
        "  openai.api_key = ' '.join(f.readlines())\n",
        "\n",
        "# Update the OpenAI API key by updating the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxNxROrDrf2S"
      },
      "source": [
        "### Apis for extracting texts and attachments from the email (eml files with attachments as pdf, doc, images or another eml file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "657383ef"
      },
      "source": [
        "### üì© Email Content Extraction\n",
        "This function reads `.eml` files, extracts text from email body and attachments, and supports nested `.eml` processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnUlGmwDqYPz",
        "outputId": "17fca1b8-9827-467e-b04c-4a1b5f6a4af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import email\n",
        "import easyocr\n",
        "import pdfplumber\n",
        "import traceback\n",
        "import numpy as np\n",
        "from email import policy\n",
        "from email.parser import BytesParser\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup  # For HTML parsing\n",
        "\n",
        "# Initialize EasyOCR Reader\n",
        "ocr_reader = easyocr.Reader([\"en\"])  # Specify language (English)\n",
        "\n",
        "def extract_text_from_pdf_bytes(pdf_bytes):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                extracted = page.extract_text()\n",
        "                if extracted:\n",
        "                    text += extracted + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PDF Extraction Error: {str(e)}\")\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_docx_bytes(doc_bytes):\n",
        "    \"\"\"Extract text from a DOCX file.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        doc_stream = BytesIO(doc_bytes)\n",
        "        doc = Document(doc_stream)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå DOC/DOCX Extraction Error: {str(e)}\")\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_image(image_bytes):\n",
        "    \"\"\"Extract text from images using EasyOCR.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        img = Image.open(BytesIO(image_bytes))\n",
        "        results = ocr_reader.readtext(np.array(img))  # Convert Image to NumPy array\n",
        "        text = \"\\n\".join([res[1] for res in results])\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Image Extraction Error: {str(e)}\")\n",
        "    return text.strip()\n",
        "\n",
        "def process_eml_bytes(eml_bytes, is_nested=False):\n",
        "    \"\"\"Processes an EML file given as bytes, handling nested emails properly.\"\"\"\n",
        "    try:\n",
        "        msg = BytesParser(policy=policy.default).parse(BytesIO(eml_bytes))\n",
        "\n",
        "        email_data = {\n",
        "            \"subject\": msg[\"subject\"],\n",
        "            \"from\": msg[\"from\"],\n",
        "            \"to\": msg[\"to\"],\n",
        "            \"date\": msg[\"date\"],\n",
        "            \"body\": \"\",\n",
        "            \"attachments\": []\n",
        "        }\n",
        "\n",
        "        # Extract email body (only for non-nested emails)\n",
        "        if not is_nested:\n",
        "            body_text = []\n",
        "            for part in msg.walk():\n",
        "                content_type = part.get_content_type()\n",
        "                content_disposition = str(part.get(\"Content-Disposition\", \"\"))\n",
        "\n",
        "                # Extract text/plain parts, but exclude nested emails\n",
        "                if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
        "                    decoded_text = part.get_payload(decode=True).decode(errors=\"ignore\").strip()\n",
        "                    if decoded_text:\n",
        "                        body_text.append(decoded_text)\n",
        "\n",
        "                # Extract HTML content if plain text is empty\n",
        "                elif content_type == \"text/html\" and not body_text:\n",
        "                    soup = BeautifulSoup(part.get_payload(decode=True), \"html.parser\")\n",
        "                    decoded_text = soup.get_text().strip()\n",
        "                    if decoded_text:\n",
        "                        body_text.append(decoded_text)\n",
        "\n",
        "            email_data[\"body\"] = \"\\n\".join(body_text).strip()\n",
        "\n",
        "        # Process attachments\n",
        "        for part in msg.walk():\n",
        "            content_type = part.get_content_type()\n",
        "            content_disposition = str(part.get(\"Content-Disposition\", \"\"))\n",
        "            file_name = part.get_filename()\n",
        "            payload = part.get_payload(decode=True)  # Decode base64 content\n",
        "            extracted_text = \"\"\n",
        "\n",
        "            if not file_name and content_type == \"message/rfc822\":\n",
        "                # Gmail often stores nested EMLs without a filename\n",
        "                file_name = \"nested_email.eml\"\n",
        "\n",
        "            if not file_name:\n",
        "                continue  # Ignore if no filename is found\n",
        "\n",
        "            # Handle PDFs\n",
        "            if content_type in [\"application/pdf\", \"application/octet-stream\"] and file_name.lower().endswith(\".pdf\"):\n",
        "                extracted_text = extract_text_from_pdf_bytes(payload)\n",
        "\n",
        "            # Handle Word Documents\n",
        "            elif content_type in [\"application/msword\", \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"] or file_name.lower().endswith((\".doc\", \".docx\")):\n",
        "                extracted_text = extract_text_from_docx_bytes(payload)\n",
        "\n",
        "            # Handle Images\n",
        "            elif content_type.startswith(\"image/\") or (content_type == \"application/octet-stream\" and file_name.lower().endswith((\"png\", \"jpg\", \"jpeg\"))):\n",
        "                extracted_text = extract_text_from_image(payload)\n",
        "\n",
        "            # Handle nested EML files (Gmail nested emails included)\n",
        "            elif content_type == \"message/rfc822\" or (content_type == \"application/octet-stream\" and file_name.lower().endswith(\".eml\")):\n",
        "                nested_email_data = process_eml_bytes(payload, is_nested=True)  # Process as nested email\n",
        "\n",
        "                email_data[\"attachments\"].append({\n",
        "                    \"file_name\": file_name,\n",
        "                    \"content_type\": content_type,\n",
        "                    \"nested_email\": nested_email_data  # Store full nested email structure instead of text\n",
        "                })\n",
        "                continue  # Skip normal processing for nested emails\n",
        "\n",
        "            email_data[\"attachments\"].append({\n",
        "                \"file_name\": file_name,\n",
        "                \"content_type\": content_type,\n",
        "                \"extracted_text\": extracted_text\n",
        "            })\n",
        "\n",
        "        return email_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Email Parsing Error: {traceback.format_exc()}\")\n",
        "        return None\n",
        "\n",
        "def process_eml_file(eml_path):\n",
        "    \"\"\"Processes an EML file from a given file path and extracts email content and attachments.\"\"\"\n",
        "    try:\n",
        "        with open(eml_path, \"rb\") as f:\n",
        "            eml_bytes = f.read()\n",
        "        return process_eml_bytes(eml_bytes)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing EML file ({eml_path}): {str(e)}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57db8ae8"
      },
      "source": [
        "### Email Content Extraction - Test function\n",
        "This function reads `.eml` files, extracts text from email body and attachments, and supports nested `.eml` processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5gQQVAkxZeM",
        "outputId": "7d543067-ec0a-4014-d892-01bd7c03d255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì© Processed Email: {'subject': 'Loan Information Request: Balance Inquiry', 'from': 'accounts@businessxyz.com', 'to': 'billing@wellsfargo.com', 'date': None, 'body': 'Dear Billing Team,\\n\\nI would like to request the following loan information.\\n\\nAccount Number: 4455667788\\nRequested Information: Current outstanding loan balance\\n\\nAttached is a document with further details.\\n\\nBest regards,\\nCustomer Support', 'attachments': [{'file_name': 'balance_inquiry_details.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'Loan Information Request Details\\nAccount Number: 4455667788\\nRequested Information: Current outstanding loan balance'}]}\n",
            "üì© Processed Email: {'subject': 'Loan Information Request: Amortization Schedule', 'from': 'accounts@businessxyz.com', 'to': 'billing@wellsfargo.com', 'date': None, 'body': 'Dear Billing Team,\\n\\nI would like to request the following loan information.\\n\\nAccount Number: 5566778899\\nRequested Information: Full amortization schedule including principal and interest breakdown\\n\\nAttached is a document with further details.\\n\\nBest regards,\\nCustomer Support', 'attachments': [{'file_name': 'amortization_schedule_details.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'Loan Information Request Details\\nAccount Number: 5566778899\\nRequested Information: Full amortization schedule including principal and interest breakdown'}]}\n",
            "üì© Processed Email: {'subject': 'Closing Notice: Reallocation of Fees for Loan', 'from': 'jack.sparow@citizensbank.com', 'to': 'wallace.scot@wellsfargo.com', 'date': None, 'body': 'BOA Bank, N.A.\\nLoan Agency Services\\n\\nDate: 05-Feb-2025\\n\\nTO: WELLS FARGO BANK, NATIONAL ASSOCIATION\\nATTN: RAMAKRISHNA KUNCHALA\\nFax: 877-606-9426\\n\\nRe: ABTB MID-ATLANTIC LLC $171.3MM 11-4-2022, TERM LOAN A-2\\n\\nDescription: Closing Notice: Reallocation of Fees for Loan\\nBORROWER: ABTB MID-ATLANTIC LLC\\nDEAL NAME: ABB MID-ATLANTIC LLC $171.3MM 11-4-2022\\n\\nDear Scot,\\n\\nThis notice confirms the reallocation of fees for the [Deal Name] transaction.\\nEffective Date: 24-Mar-2025\\nFee Type: Transaction\\nReallocation Amount: 150.00 USD\\nWe appreciate your continued partnership.\\n\\nSincerely,\\nJack', 'attachments': [{'file_name': 'attachment_sample.pdf', 'content_type': 'application/octet-stream', 'extracted_text': '# BANK OF AMERICA\\n# Bank of America, N.A.\\n# To: WELLS FARGO BANK NATIONAL ASSOCIATION\\n# Date: 8-Nov-2023\\n# ATTN:\\n# Phone: 999-999-9999\\n# Fax: 877-606-9426\\n# Email: DENLCFX@wellsfargo.com\\n# Re: CANTOR FITZGERALD LP USD 425MM MAR22 / REVOLVER / CANTOR FIT00037\\n# Deal CUSIP: 13861EAE0\\n# Deal ISIN: US13861EAE05\\n# Facility CUSIP: 13861EAF7\\n# Facility ISIN: US13861EAF79\\n# Lender MEI: US1L058422\\n# Effective 10-Nov-2023, CANTOR FITZGERALD LP has elected to repay under the SOFR (US) Term option, a total of USD 20,000,000.00.\\n# Previous Global principal balance: USD 45,000,000.00\\n# New Global principal balance: USD 25,000,000.00\\n# Your share of the USD 20,000,000.00 SOFR (US) Term option payment is USD 1,411,764.71.\\n# Previous Lender Share Principal Balance: USD 3,176,470.59\\n# New Lender Share Principal Balance: USD 1,764,705.88\\n# We will remit USD 1,411,764.71 on the effective date. Please note that:\\n# (i) if the Borrower has not in fact made such payment; or\\n# (ii) any payment you receive is in excess of what was paid by the Borrower or\\n# (iii) we notify you that the payment was erroneously made, then pursuant to the provisions of the credit facility, you agree to return such payment.\\n# For: WELLS FARGO BANK NATIONAL ASSOCIATION\\n# To: WELLS FARGO BANK, NA\\n# ABA Number: 121000248\\n# Account No: XXXXXXXXXX0720\\n# Reference: CANTOR FITZGERALD LP USD 425MM MAR22, SOFR (US) Term Principal Payment (CANTOR FIT00037)\\n# Thanks & Regards,\\n# JONNY HERNANDEZ\\n# Telephone #: +19803883225\\n# Email id: jonny.hernandez@bofa.com\\nLOAN AGREEMENT\\nThis Loan Agreement (\"Agreement\") is made and entered into as of [Date] by and between:\\n[Borrower Name], with a principal place of business at [Borrower Address] (\"Borrower\"), and\\n[Lender Name], a [State] corporation with a principal place of business at [Lender Address] (\"Lender\").\\nWHEREAS, Borrower desires to obtain a loan from Lender in the principal amount of [Loan Amount] (the \"Loan\"); and\\nWHEREAS, Lender is willing to make the Loan to Borrower upon the terms and conditions hereinafter set forth.\\nNOW, THEREFORE, in consideration of the mutual covenants and agreements contained herein, the parties agree as follows:\\n1. Loan. Lender hereby agrees to lend to Borrower, and Borrower hereby agrees to borrow from Lender, the principal amount of the Loan.\\n2. Interest. The Loan shall bear interest at a rate of [Interest Rate] per annum, payable [Payment Frequency].\\n3. Term. The Loan shall have a term of [Loan Term], commencing on [Start Date] and ending on [End Date].\\n4. Repayment. Borrower shall repay the Loan in accordance with the amortization schedule attached hereto as Exhibit A.\\n5. Security. The Loan shall be secured by a mortgage on the property located at [Property Address] (the \"Property\").\\n6. Events of Default. The occurrence of any of the following events shall constitute an event of default under this Agreement:\\na. Failure to make any payment of principal or interest when due.\\nb. Breach of any other material provision of this Agreement.\\nc. Filing of a petition for bankruptcy by Borrower.\\n7. Remedies. Upon the occurrence of an event of default, Lender shall have the right to exercise any and all remedies available to it under applicable law, including but not limited to:\\na. Acceleration of the maturity of the Loan.\\nb. Foreclosure on the Property.\\n8. Governing Law. This Agreement shall be governed by and construed in accordance with the laws of the State of [State].\\n9. Entire Agreement. This Agreement constitutes the entire agreement and understanding between the parties with respect to the subject matter hereof and supersedes all prior or contemporaneous communications, representations, or agreements, whether oral or written.\\n10. Notices. All notices and other communications hereunder shall be in writing and shall be deemed to have been duly given when delivered personally, sent by certified mail, return receipt requested, or sent by reputable overnight courier service, addressed as follows:\\nIf to Borrower:\\n[Borrower Name]\\n[Borrower Address]\\nIf to Lender:\\n[Lender Name]\\n[Lender Address]\\n11. Waivers. No waiver of any provision of this Agreement shall be effective unless in writing and signed by the party against whom the waiver is sought to be enforced.\\n12. Severability. If any provision of this Agreement is held to be invalid or unenforceable, such provision shall be struck from this Agreement and the remaining provisions shall remain in full force and effect.\\n13. Binding Effect. This Agreement shall be binding upon and inure to the benefit of the parties hereto and their respective successors and permitted assigns.\\nIN WITNESS WHEREOF, the parties have executed this Agreement as of the date first written above.\\n[Borrower Signature]\\n[Borrower Name]\\nTest Lndere'}]}\n",
            "üì© Processed Email: {'subject': 'Loan Grievance: Dispute Resolution', 'from': 'finance_dept@randomcorp.com', 'to': 'billing@wellsfargo.com', 'date': None, 'body': 'Dear Billing Team,\\n\\nI would like to submit a grievance regarding my loan account.\\n\\nAccount Number: 1122334455\\nIssue: Incorrect loan balance charged\\nRequested Action: Adjustment of balance\\n\\nAttached is the detailed document for reference.\\n\\nBest regards,\\nCustomer Support', 'attachments': [{'file_name': 'dispute_resolution_details.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'Loan Grievance Details\\nAccount Number: 1122334455\\nIssue: Incorrect loan balance charged\\nRequested Action: Adjustment of balance'}]}\n",
            "üì© Processed Email: {'subject': 'Payment Request: Letter of Credit Fee Payment', 'from': 'billing@enterpriseabc.com', 'to': 'billing@wellsfargo.com', 'date': None, 'body': 'Dear Billing Team,\\n\\nPlease process the payment for the following fee:\\n\\nAccount Number: 987654321\\nFee Type: Letter of Credit Fee\\nAmount: $12,500.00\\nDue Date: April 15, 2025\\n\\nAttached are the transaction details for reference.\\n\\nBest regards,\\nFinance Department', 'attachments': [{'file_name': 'letter_of_credit_fee_details.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'Transaction Details\\nAccount Number: 987654321\\nFee Type: Letter of Credit Fee\\nAmount: $12,500.00\\nDue Date: April 15, 2025'}]}\n",
            "üì© Processed Email: {'subject': 'Loan Grievance: Complaint Registration', 'from': 'accounts@businessxyz.com', 'to': 'billing@wellsfargo.com', 'date': None, 'body': 'Dear Billing Team,\\n\\nI would like to submit a grievance regarding my loan account.\\n\\nAccount Number: 2233445566\\nIssue: Delayed processing of loan payment\\nRequested Action: Expedited processing\\n\\nAttached is the detailed document for reference.\\n\\nBest regards,\\nCustomer Support', 'attachments': [{'file_name': 'complaint_registration_details.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'Loan Grievance Details\\nAccount Number: 2233445566\\nIssue: Delayed processing of loan payment\\nRequested Action: Expedited processing'}]}\n",
            "‚ùå PDF Extraction Error: No /Root object! - Is this really a PDF?\n",
            "üì© Processed Email: {'subject': 'Facility Lender Share Adjustment', 'from': 'scott.wallace@citizensbank.com', 'to': 'ramakrishna.kunchala@wellsfargo.com', 'date': None, 'body': 'Citizens Bank, N.A.\\nLoan Agency Services\\n\\nDate: 07-Feb-2025\\n\\nTO: WELLS FARGO BANK, NATIONAL ASSOCIATION\\nATTN: RAMAKRISHNA KUNCHALA\\nFax: 877-606-9426\\n\\nRe: ABTB MID-ATLANTIC LLC $171.5MM 11-4-2022, TERM LOAN A-2\\n\\nDescription: Facility Lender Share Adjustment\\nBORROWER: ABTB MID-ATLANTIC LLC\\nDEAL NAME: ABB MID-ATLANTIC LLC $171.5MM 11-4-2022\\n\\nEffective 06-Feb-2025, the Lender Shares of facility TERM LOAN A-2 have been adjusted.\\nYour share of the commitment was USD 5,520,000.19. It has been Increased to USD 5,543,000.55.\\n\\nFor: WELLS FARGO BANK, NA\\nReference: ABIB MID-ATLANTIC LIC $171.5MM 11-4-2022\\n\\nIf you have any questions, please call the undersigned.\\n\\n** COMMENT *\\nPLEASE FUND YOUR SHARE OF $23,500.00\\n\\nBank Name: Citizens Bank NA\\nABA # 011500120\\nAccount #: 0026693011\\nAccount Name: LIQ CLO Operating Account\\nRef: ABTB Mid-Atlantic LLC\\n\\nRegards,\\nSCOTT WALLACE', 'attachments': [{'file_name': 'attachment.pdf', 'content_type': 'application/octet-stream', 'extracted_text': ''}]}\n",
            "üì© Processed Email: {'subject': 'Facility Lender Share Adjustment', 'from': 'scott.wallace@citizensbank.com', 'to': 'ramakrishna.kunchala@wellsfargo.com', 'date': None, 'body': 'Citizens Bank, N.A.\\nLoan Agency Services\\n\\nDate: 05-Feb-2025\\n\\nTO: WELLS FARGO BANK, NATIONAL ASSOCIATION\\nATTN: RAMAKRISHNA KUNCHALA\\nFax: 877-606-9426\\n\\nRe: ABTB MID-ATLANTIC LLC $171.3MM 11-4-2022, TERM LOAN A-2\\n\\nDescription: Facility Lender Share Adjustment\\nBORROWER: ABTB MID-ATLANTIC LLC\\nDEAL NAME: ABB MID-ATLANTIC LLC $171.3MM 11-4-2022\\n\\nEffective 04-Feb-2025, the Lender Shares of facility TERM LOAN A-2 have been adjusted.\\nYour share of the commitment was USD 5,518,249.19. It has been Increased to USD 5,542,963.55.\\n\\nFor: WELLS FARGO BANK, NA\\nReference: ABIB MID-ATLANTIC LIC $171.3MM 11-4-2022\\n\\nIf you have any questions, please call the undersigned.\\n\\n** COMMENT *\\nPLEASE FUND YOUR SHARE OF $24,714.36\\n\\nBank Name: Citizens Bank NA\\nABA # 011500120\\nAccount #: 0026693011\\nAccount Name: LIQ CLO Operating Account\\nRef: ABTB Mid-Atlantic LLC\\n\\nRegards,\\nSCOTT WALLACE', 'attachments': [{'file_name': 'attachment.pdf', 'content_type': 'application/octet-stream', 'extracted_text': 'BANK OF AMERICA\\nBank of America, N.A.\\nTo: WELLS FARGO BANK NATIONAL ASSOCIATION\\nDate: 8-Nov-2023\\nATTN:\\nPhone: 999-999-9999\\nFax: 877-606-9426\\nEmail: DENLCFX@wellsfargo.com\\nRe: CANTOR FITZGERALD LP USD 425MM MAR22 / REVOLVER / CANTOR FIT00037\\nDeal CUSIP: 13861EAE0\\nDeal ISIN: US13861EAE05\\nFacility CUSIP: 13861EAF7\\nFacility ISIN: US13861EAF79\\nLender MEI: US1L058422\\nEffective 10-Nov-2023, CANTOR FITZGERALD LP has elected to repay under the SOFR (US) Term option, a total of USD 20,000,000.00.\\nPrevious Global principal balance: USD 45,000,000.00\\nNew Global principal balance: USD 25,000,000.00\\nYour share of the USD 20,000,000.00 SOFR (US) Term option payment is USD 1,411,764.71.\\nPrevious Lender Share Principal Balance: USD 3,176,470.59\\nNew Lender Share Principal Balance: USD 1,764,705.88\\nWe will remit USD 1,411,764.71 on the effective date. Please note that:\\n(i) if the Borrower has not in fact made such payment; or\\n(ii) any payment you receive is in excess of what was paid by the Borrower or\\n(iii) we notify you that the payment was erroneously made, then pursuant to the provisions of the credit facility, you agree to return such payment.\\nFor: WELLS FARGO BANK NATIONAL ASSOCIATION\\nTo: WELLS FARGO BANK, NA\\nABA Number: 121000248\\nAccount No: XXXXXXXXXX0720\\nReference: CANTOR FITZGERALD LP USD 425MM MAR22, SOFR (US) Term Principal Payment (CANTOR FIT00037)\\nThanks & Regards,\\nJONNY HERNANDEZ\\nTelephone #: +19803883225\\nEmail id: jonny.hernandez@bofa.com'}]}\n"
          ]
        }
      ],
      "source": [
        "EMAIL_DIR = \"/content/drive/MyDrive/EmailClassification/emails/\"\n",
        "for eml_file in os.listdir(EMAIL_DIR):\n",
        "    if eml_file.endswith(\".eml\"):\n",
        "        # Step 1: Process email and extract content\n",
        "        processed_email = process_eml_file(os.path.join(EMAIL_DIR, eml_file))\n",
        "        print(\"üì© Processed Email:\", processed_email)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A-evhsPLDxf"
      },
      "source": [
        "### Function Calling Api to Extract Request & sub request in json format\n",
        "Using the Function Calling API to create a function schema to extract data directly into the defined JSON format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "GKkD-3F_tdrU"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"classify_email\",\n",
        "        \"description\": \"Classifies the email into a request type and sub-request type.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"request_type\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The high-level category of the request based on the primary intent of the email.\"\n",
        "                },\n",
        "                \"sub_request_type\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The specific sub-category under the request type based on the primary intent of the email.\"\n",
        "                },\n",
        "                \"duplicate_flag\": {\n",
        "                    \"type\": \"boolean\",\n",
        "                    \"description\": \"Flag to indicate if the email is a duplicate.\"\n",
        "                },\n",
        "                \"confidence_score\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"Confidence score between 0 and 1.\"\n",
        "                },\n",
        "                \"reason\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Explanation for classification and confidence score.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"request_type\",\n",
        "                \"sub_request_type\",\n",
        "                \"duplicate_flag\",\n",
        "                \"confidence_score\",\n",
        "                \"reason\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwp_amRLUNU"
      },
      "source": [
        "### Create Pormpt for email classification with request type, sub request type, confidence score, reason for classification and duplicate check flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9IhiaPUcvpK0"
      },
      "outputs": [],
      "source": [
        "def create_email_classification_prompt(email_text, duplicate_flag, additional_rules=None, additional_request_types=None):\n",
        "    # Default Predefined Request Types\n",
        "    predefined_request_types = \"\"\"\n",
        "    Request Types:\n",
        "\n",
        "    - Adjustment: (Subtypes: Fee Adjustment, Principal Adjustment, Interest Adjustment)\n",
        "    - AU Transfer: (Subtypes: Intra-Bank Transfer, Inter-Bank Transfer, Scheduled Transfer)\n",
        "    - Closing Notice: (Subtypes: Reallocation Fees, Amendment Fees, Reallocation Principal)\n",
        "    - Commitment Change: (Subtypes: Cashless Roll, Decrease, Increase)\n",
        "    - Fee Payment: (Subtypes: Ongoing Fee, Letter of Credit Fee)\n",
        "    - Money Movement-Inbound: (Subtypes: Principal, Interest, Principal + Interest, Principal+Interest+Fee)\n",
        "    - Money Movement-Outbound: (Subtypes: Timebound, Foreign Currency)\n",
        "    - Loan Origination: (Subtypes: Application Submission, Documentation Provision, Credit Evaluation, Approval Notification)\n",
        "    - Loan Disbursement: (Subtypes: Fund Transfer, Disbursement Schedule, Disbursement Confirmation)\n",
        "    - Loan Repayment: (Subtypes: Repayment Schedule Setup, Early Repayment, Payment Rescheduling, Payment Confirmation)\n",
        "    - Loan Information: (Subtypes: Balance Inquiry, Amortization Schedule, Interest Statement, Tax Certificate)\n",
        "    - Loan Closure: (Subtypes: Closure Statement, No Dues Certificate, Security Release)\n",
        "    - Loan Service: (Subtypes: Statement Requests, Document Retrieval, Account Linking)\n",
        "    - Loan Grievance: (Subtypes: Dispute Resolution, Complaint Registration, Feedback Submission)\n",
        "    \"\"\"\n",
        "\n",
        "    # Append Additional Request Types if Provided\n",
        "    if additional_request_types:\n",
        "        predefined_request_types += f\"\\n\\n### Additional Request Types & Subtypes:\\n{additional_request_types}\"\n",
        "\n",
        "    # Default Priority Considerations\n",
        "    priority_considerations = \"\"\"\n",
        "    **Priority Considerations:**\n",
        "    1. **Email body takes priority** over attachments for classification.\n",
        "    2. **Primary intent of the customer is the key focus**, even when multiple requests are mentioned.\n",
        "    3. If an email contains **both a discussion and an explicit ask**, prioritize the **ask** as the primary intent.\n",
        "    4. **Money movement-related requests take priority** in case of conflicts.\n",
        "    5. Mark **duplicate emails** based on the flag extracted from similarity search of earlier emails, which is **{duplicate_flag}**.\n",
        "    6. If multiple request types are identified, explain the reson for prioritization in the reason field.\n",
        "    \"\"\"\n",
        "\n",
        "    # Append Additional Rules if Provided\n",
        "    if additional_rules:\n",
        "        priority_considerations += f\"\\n\\n### Additional Classification Rules:\\n{additional_rules}\"\n",
        "\n",
        "    # Construct the Classification Prompt\n",
        "    classification_prompt = f\"\"\"\n",
        "    You are a subject matter expert in Commercial Bank Lending Services, responsible for classifying emails into predefined **Request Types** and **Sub Request Types**.\n",
        "\n",
        "    {priority_considerations}\n",
        "\n",
        "    **Predefined Request Categories & Subtypes:**\n",
        "    {predefined_request_types}\n",
        "\n",
        "    **Task:**\n",
        "    - Analyze the email and classify it into the most relevant **Request Type** and **Sub Request Type**.\n",
        "    - Provide a **confidence score** (0.0 to 1.0) indicating the likelihood of correct classification.\n",
        "    - Explain the **reasoning** for classification.\n",
        "\n",
        "    **Email Content for Classification:**\n",
        "    \"{email_text}\"\n",
        "\n",
        "    **Output Format (JSON):**\n",
        "    {{\n",
        "        \"request_type\": \"Determined request type based on primary intent\",\n",
        "        \"sub_request_type\": \"Determined sub-request type\",\n",
        "        \"duplicate_flag\": {duplicate_flag},\n",
        "        \"confidence_score\": confidence_value (between 0-1),\n",
        "        \"reason\": \"Explanation for classification and confidence score\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a subject matter expert in Commercial Bank Lending Services. Your task is to classify emails and determine the request type and sub-request type with high accuracy.\"},\n",
        "        {\"role\": \"user\", \"content\": classification_prompt}\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSF-GGf6LSln"
      },
      "source": [
        "### Create Pormpt for extracting metadata fields from the email based on the extracted request type and sub request type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "tR5MGKr4LSH1"
      },
      "outputs": [],
      "source": [
        "def create_metadata_fields_extraction_prompt(email_text, request_type, sub_request_type):\n",
        "  metadata_fields_mapping = {\n",
        "      \"Adjustment - Fee Adjustment\": [\"deal_name\", \"adjustment_amount\", \"effective_date\", \"lender_name\", \"reason\"],\n",
        "      \"Adjustment - Principal Adjustment\": [\"deal_name\", \"principal_amount\", \"effective_date\", \"lender_name\"],\n",
        "      \"Adjustment - Interest Adjustment\": [\"deal_name\", \"interest_amount\", \"effective_date\", \"lender_name\"],\n",
        "\n",
        "      \"AU Transfer - Intra-Bank Transfer\": [\"transfer_id\", \"source_account_number\", \"destination_account_number\", \"transfer_amount\", \"transfer_date\"],\n",
        "      \"AU Transfer - Inter-Bank Transfer\": [\"transfer_id\", \"source_bank\", \"destination_bank\", \"transfer_amount\", \"transfer_date\"],\n",
        "      \"AU Transfer - Scheduled Transfer\": [\"transfer_id\", \"source_account_number\", \"destination_account_number\", \"transfer_amount\", \"scheduled_date\"],\n",
        "\n",
        "      \"Closing Notice - Reallocation Fees\": [\"deal_name\", \"fee_type\", \"reallocation_amount\", \"effective_date\", \"lender_name\"],\n",
        "      \"Closing Notice - Amendment Fees\": [\"deal_name\", \"fee_type\", \"amendment_amount\", \"effective_date\", \"lender_name\"],\n",
        "      \"Closing Notice - Reallocation Principal\": [\"deal_name\", \"principal_amount\", \"effective_date\", \"lender_name\"],\n",
        "\n",
        "      \"Commitment Change - Cashless Roll\": [\"deal_name\", \"lender_name\", \"commitment_type\", \"amount_rolled\", \"effective_date\"],\n",
        "      \"Commitment Change - Decrease\": [\"deal_name\", \"lender_name\", \"commitment_decrease\", \"new_commitment_amount\", \"effective_date\"],\n",
        "      \"Commitment Change - Increase\": [\"deal_name\", \"lender_name\", \"commitment_increase\", \"new_commitment_amount\", \"effective_date\"],\n",
        "\n",
        "      \"Fee Payment - Ongoing Fee\": [\"fee_type\", \"due_date\", \"amount_paid\", \"outstanding_amount\", \"payment_date\", \"reference_number\"],\n",
        "      \"Fee Payment - Letter of Credit Fee\": [\"fee_type\", \"amount_paid\", \"payment_date\", \"credit_reference_number\"],\n",
        "\n",
        "      \"Money Movement - Inbound - Principal\": [\"amount\", \"currency\", \"transaction_id\", \"sender_bank\", \"receiver_bank\", \"transfer_date\"],\n",
        "      \"Money Movement - Inbound - Interest\": [\"amount\", \"currency\", \"transaction_id\", \"sender_bank\", \"receiver_bank\", \"transfer_date\"],\n",
        "      \"Money Movement - Inbound - Principal + Interest\": [\"total_amount\", \"currency\", \"transaction_id\", \"sender_bank\", \"receiver_bank\", \"transfer_date\"],\n",
        "      \"Money Movement - Outbound - Timebound\": [\"amount\", \"currency\", \"transaction_id\", \"receiver_bank\", \"transfer_date\", \"time_constraint\"],\n",
        "      \"Money Movement - Outbound - Foreign Currency\": [\"amount\", \"currency\", \"exchange_rate\", \"transaction_id\", \"receiver_bank\", \"transfer_date\"],\n",
        "\n",
        "      \"Loan Origination - Application Submission\": [\"borrower_name\", \"loan_application_id\", \"requested_amount\", \"submission_date\"],\n",
        "      \"Loan Origination - Documentation Provision\": [\"borrower_name\", \"document_type\", \"submission_date\"],\n",
        "      \"Loan Origination - Credit Evaluation\": [\"borrower_name\", \"credit_score\", \"evaluation_date\"],\n",
        "      \"Loan Origination - Approval Notification\": [\"borrower_name\", \"loan_application_id\", \"approval_status\", \"approval_date\"],\n",
        "\n",
        "      \"Loan Disbursement - Fund Transfer\": [\"fund_transfer_id\", \"disbursement_amount\", \"disbursement_date\", \"beneficiary_account\"],\n",
        "      \"Loan Disbursement - Disbursement Schedule\": [\"loan_id\", \"disbursement_plan\", \"schedule_dates\"],\n",
        "      \"Loan Disbursement - Disbursement Confirmation\": [\"loan_id\", \"confirmation_date\", \"amount_disbursed\"],\n",
        "\n",
        "      \"Loan Repayment - Repayment Schedule Setup\": [\"loan_id\", \"installment_amount\", \"payment_due_date\", \"repayment_term\"],\n",
        "      \"Loan Repayment - Early Repayment\": [\"loan_id\", \"remaining_balance\", \"early_repayment_date\"],\n",
        "      \"Loan Repayment - Payment Rescheduling\": [\"loan_id\", \"new_payment_schedule\", \"reschedule_reason\"],\n",
        "      \"Loan Repayment - Payment Confirmation\": [\"loan_id\", \"payment_date\", \"amount_paid\"],\n",
        "\n",
        "      \"Loan Information - Balance Inquiry\": [\"account_number\", \"current_balance\", \"last_transaction_date\"],\n",
        "      \"Loan Information - Amortization Schedule\": [\"loan_id\", \"remaining_payments\", \"monthly_installment\"],\n",
        "      \"Loan Information - Interest Statement\": [\"loan_id\", \"interest_rate\", \"accrued_interest\", \"statement_period\"],\n",
        "      \"Loan Information - Tax Certificate\": [\"borrower_name\", \"loan_id\", \"tax_year\", \"interest_paid\"],\n",
        "\n",
        "      \"Loan Closure - Closure Statement\": [\"loan_id\", \"closure_date\", \"final_payment_amount\"],\n",
        "      \"Loan Closure - No Dues Certificate\": [\"loan_id\", \"certificate_issue_date\"],\n",
        "      \"Loan Closure - Security Release\": [\"loan_id\", \"release_date\", \"security_details\"],\n",
        "\n",
        "      \"Loan Service - Statement Requests\": [\"account_number\", \"statement_period\", \"delivery_preference\"],\n",
        "      \"Loan Service - Document Retrieval\": [\"document_type\", \"request_date\", \"delivery_preference\"],\n",
        "      \"Loan Service - Account Linking\": [\"primary_account_number\", \"linked_account_number\", \"linking_type\"],\n",
        "\n",
        "      \"Loan Grievance - Dispute Resolution\": [\"dispute_id\", \"dispute_description\", \"resolution_status\", \"resolution_date\"],\n",
        "      \"Loan Grievance - Complaint Registration\": [\"complaint_id\", \"complaint_category\", \"complaint_details\"],\n",
        "      \"Loan Grievance - Feedback Submission\": [\"feedback_id\", \"feedback_category\", \"feedback_text\"]\n",
        "    }\n",
        "\n",
        "  # Lookup metadata fields using request_type + sub_request_type\n",
        "  metadata_fields = metadata_fields_mapping.get(\n",
        "      f\"{request_type} - {sub_request_type}\",\n",
        "      metadata_fields_mapping.get(request_type, [])\n",
        "  )\n",
        "\n",
        "  metadata_prompt = f\"\"\"\n",
        "  You are an AI assistant specializing in extracting **structured metadata** from emails related to Commercial Bank Lending Services.\n",
        "\n",
        "  **Your task:**\n",
        "  - Extract only the metadata fields relevant to **Request Type: {request_type}** and **Sub-Request Type: {sub_request_type}** and provide the output content in a json format.\n",
        "  - Ignore classification details like request type, confidence score, or reasoning.\n",
        "  - Extract metadata **only as key-value pairs**, ensuring values are **explicitly mentioned in the email text**.\n",
        "  - **Expected Metadata Fields:** {', '.join(metadata_fields)}\n",
        "  - If metadata_fields is empty, identify the possible metadata_fields based on the request_type {request_type}, sub_request_type {sub_request_type} and your knowledge in commercial bank lending service and prepare a json by extracting corresponding values in the format given in few shot examples.\n",
        "  - **Output must be a flat JSON object** with key-value pairs.\n",
        "  - If no valid metadata is found, output  an empty json response.\n",
        "\n",
        "  ---\n",
        "  **Email Content for Metadata Extraction:**\n",
        "  \"{email_text}\"\n",
        "\n",
        "  ---\n",
        "  **Example 1: Commitment Change - Increase**\n",
        "  **Email:**\n",
        "  \"Dear Loan Team,\n",
        "  We request an increase in our commitment under the ABC Infrastructure Fund.\n",
        "  Our current commitment is $2,000,000, and we would like to increase it to $2,500,000.\n",
        "  Please process this request and confirm.\n",
        "\n",
        "  Regards,\n",
        "  John Doe, CFO, XYZ Corp\"\n",
        "\n",
        "  **Expected JSON Output:**\n",
        "  {{\n",
        "      \"deal_name\": \"ABC Infrastructure Fund\",\n",
        "      \"lender_name\": \"XYZ Corp\",\n",
        "      \"commitment_increase\": \"USD 500,000\",\n",
        "      \"new_commitment_amount\": \"USD 2,500,000\"\n",
        "  }}\n",
        "\n",
        "  ---\n",
        "  **üö® IMPORTANT:**\n",
        "  - Ensure **every field** has a value.\n",
        "  - If no metadata is found, return an empty json response.\n",
        "  - **Final Output Format:**\n",
        "  {{\n",
        "      \"field_1\": \"Extracted value\",\n",
        "      \"field_2\": \"Extracted value\"\n",
        "  }}\n",
        "  \"\"\"\n",
        "\n",
        "  return [\n",
        "      {\"role\": \"system\", \"content\": \"You are an expert AI model trained to extract metadata fields from commercial banking emails. You return only key-value pairs without classification details.\"},\n",
        "      {\"role\": \"user\", \"content\": metadata_prompt}\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16c42942"
      },
      "source": [
        "### üìå Email Classification\n",
        "Uses **GPT-3.5-turbo** to classify emails into predefined request types and sub-request types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_R6G4HzDMYPM"
      },
      "outputs": [],
      "source": [
        "def get_email_classification(email_text, duplicate_flag, functions, additional_rules=None, additional_request_types=None):\n",
        "    user_input = create_email_classification_prompt(email_text, duplicate_flag, additional_rules, additional_request_types)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=user_input,\n",
        "        functions=functions,\n",
        "        function_call=\"auto\"\n",
        "    )\n",
        "    return response.choices[0].message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7686f2be"
      },
      "source": [
        "### üìä Metadata Extraction\n",
        "Uses **GPT-4-turbo** to extract relevant metadata fields from classified emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-pFqsYqaMZPu"
      },
      "outputs": [],
      "source": [
        "def get_metadata_fields(email_text, request_type, sub_request_type, functions):\n",
        "    user_input = create_metadata_fields_extraction_prompt(email_text, request_type, sub_request_type)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        messages=user_input,\n",
        "        functions=functions,\n",
        "        function_call=\"auto\"\n",
        "    )\n",
        "    return response.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "jOf9iOx4v9BP"
      },
      "outputs": [],
      "source": [
        "def compute_email_embedding(embedding_model, email_text):\n",
        "    \"\"\"Converts email text into an embedding vector compatible with ChromaDB.\"\"\"\n",
        "    return embedding_model.encode(email_text, convert_to_numpy=True).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e32cab3"
      },
      "source": [
        "### üîç Duplicate Email Detection\n",
        "Uses **ChromaDB** and **cosine similarity search** to detect duplicate emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "1xtuh0G_oPeY"
      },
      "outputs": [],
      "source": [
        "def check_duplicate_email(email_collection, embedding_model, email_text, threshold=0.90):\n",
        "    \"\"\"Checks if the email is a duplicate by performing similarity search in ChromaDB.\"\"\"\n",
        "    email_embedding = compute_email_embedding(embedding_model, email_text)\n",
        "\n",
        "    # Perform similarity search in ChromaDB\n",
        "    results = email_collection.query(\n",
        "        query_embeddings=[email_embedding],  # Search for similar emails\n",
        "        n_results=2\n",
        "    )\n",
        "\n",
        "    for idx, distance in enumerate(results['distances'][0]):\n",
        "            # Skip the first result if it's an exact match to itself (distance = 0)\n",
        "            if idx == 0:\n",
        "                continue\n",
        "\n",
        "            if distance <= (1 - threshold):  # Check if similarity is above threshold\n",
        "                duplicate_file_id = results[\"ids\"][0][idx]\n",
        "                print(f\"‚úÖ Duplicate found: Matches {duplicate_file_id} with similarity {1 - distance:.2f}\")\n",
        "                return True, f\"{duplicate_file_id} with similarity {1 - distance:.2f}\"\n",
        "\n",
        "    return False, None  # Not a duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "NLyo0qjqxi03"
      },
      "outputs": [],
      "source": [
        "def store_email_vector(embedding_model, email_collection, unique_eml_file_id, email_text):\n",
        "    \"\"\"Stores email embedding in ChromaDB with correct formatting.\"\"\"\n",
        "    email_embedding = compute_email_embedding(embedding_model, email_text)\n",
        "\n",
        "    # Ensure embedding is a list of lists\n",
        "    if isinstance(email_embedding[0], float):\n",
        "        email_embedding = [email_embedding]  # Wrap it correctly\n",
        "\n",
        "    email_collection.add(\n",
        "        ids=[unique_eml_file_id],  # Unique eml ID\n",
        "        embeddings=email_embedding,  # Correctly formatted embedding\n",
        "        metadatas=[{\"email_text\": email_text}]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f368831"
      },
      "source": [
        "### üì© Email Content Extraction\n",
        "This function reads `.eml` files, extracts text from email body and attachments, and supports nested `.eml` processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "X-Y3IpqVvP3z"
      },
      "outputs": [],
      "source": [
        "def classify_emails_from_dir(email_dir, additional_rules=None, additional_request_types=None):\n",
        "\n",
        "  # Initialize ChromaDB\n",
        "  chroma_client = chromadb.PersistentClient(path=\"email_vectors_db\")\n",
        "  email_collection = chroma_client.get_or_create_collection(name=\"emails\")\n",
        "\n",
        "  # Load Sentence Transformer Model for Embeddings\n",
        "  embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "  # Process all emails in the directory\n",
        "  final_outputs = []  # Store final JSON outputs for all emails\n",
        "\n",
        "  for eml_file in os.listdir(EMAIL_DIR):\n",
        "      if eml_file.endswith(\".eml\"):\n",
        "          # Step 1: Process email and extract content\n",
        "          processed_email = process_eml_file(os.path.join(EMAIL_DIR, eml_file))\n",
        "          #print(\"üì© Processed Email:\", processed_email)\n",
        "\n",
        "          # Step 2: Store the email embedding first before duplicate check\n",
        "          store_email_vector(embedding_model, email_collection, eml_file, str(processed_email))\n",
        "\n",
        "          # Step 3: Check for duplicates after storing the embedding\n",
        "          duplicate_flag, duplicate_id = check_duplicate_email(email_collection, embedding_model, str(processed_email))\n",
        "\n",
        "          # If it's a duplicate, return JSON with a reason\n",
        "          if duplicate_flag:\n",
        "              duplicate_json_output = {\n",
        "                  \"eml_file_name\": eml_file,  # First element\n",
        "                  \"duplicate_flag\": True,\n",
        "                  \"reason\": f\"‚ö†Ô∏è Duplicate Email Detected! (Matches ID: {duplicate_id})\"\n",
        "              }\n",
        "              final_outputs.append(duplicate_json_output)\n",
        "              #print(\"üìú Duplicate Email JSON Output:\")\n",
        "              #print(json.dumps(duplicate_json_output, indent=4))\n",
        "              continue  # Skip further processing for duplicates\n",
        "\n",
        "          # Step 4: Classify the email\n",
        "          classification_raw = get_email_classification(processed_email, duplicate_flag, functions, additional_rules, additional_request_types)\n",
        "\n",
        "          # Convert classification response to JSON\n",
        "          classification_response = json.loads(classification_raw.function_call.arguments)\n",
        "          #print(\"üìå Classification Response:\", classification_response)\n",
        "\n",
        "          # Extract request type and sub-request type\n",
        "          request_type = classification_response.get(\"request_type\")\n",
        "          sub_request_type = classification_response.get(\"sub_request_type\")\n",
        "\n",
        "          if not request_type or not sub_request_type:\n",
        "              print(\"‚ùå Error: Missing request_type or sub_request_type.\")\n",
        "              continue  # Skip to next email\n",
        "\n",
        "          # Step 5: Extract metadata fields\n",
        "          metadata_raw = get_metadata_fields(request_type, sub_request_type, processed_email, functions)\n",
        "          # print(metadata_raw)\n",
        "\n",
        "          try:\n",
        "            if metadata_raw.content is None or str(metadata_raw.content).strip().lower() == \"none\":\n",
        "                metadata_response = {}\n",
        "            else:\n",
        "              metadata_response = json.loads(metadata_raw.content)\n",
        "          except Exception as e:\n",
        "              metadata_response = {\"error\": f\"Failed to parse metadata response: {str(e)}\"}\n",
        "\n",
        "          # print(\"üîë Metadata Response:\", metadata_response)\n",
        "\n",
        "          # Step 6: Construct final JSON output\n",
        "          final_json_output = {\n",
        "              \"eml_file_name\": eml_file,  # First element\n",
        "              **classification_response,  # Classification elements (request_type, sub_request_type, etc.)\n",
        "              \"metadata_fields\": metadata_response  # Metadata as key-value pair\n",
        "          }\n",
        "\n",
        "          final_outputs.append(final_json_output)\n",
        "\n",
        "          # Print final formatted output\n",
        "          # print(\"üìú Final JSON Output:\")\n",
        "          print(json.dumps(final_json_output, indent=4))\n",
        "  return final_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBxnVPjTOzlL"
      },
      "source": [
        "### For debugging the code without UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1305d0"
      },
      "source": [
        "### Test function to execute and see the debug statements to make sure that everything is working fine\n",
        "Processes all emails in a directory, applying classification, duplicate detection, and metadata extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "_xkCUeHCJ695"
      },
      "outputs": [],
      "source": [
        "#EMAIL_DIR = \"/content/drive/MyDrive/EmailClassification/emails/\"\n",
        "#extracted_detail_json_list = classify_emails_from_dir(EMAIL_DIR)\n",
        "#print(extracted_detail_json_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JHMoBBnyzk_"
      },
      "source": [
        "## UI code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25dd6992"
      },
      "source": [
        "### üìÇ Batch Email Processing\n",
        "Processes all emails in a directory, applying classification, duplicate detection, and metadata extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "l0o2AW90ymH1",
        "outputId": "e0bc387e-844b-45e9-bff1-2d4fab0a0d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e74f39ae99810c3b65.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e74f39ae99810c3b65.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "def format_metadata_as_html(metadata_dict):\n",
        "    \"\"\"Formats metadata fields as an HTML table.\"\"\"\n",
        "    if not metadata_dict or not isinstance(metadata_dict, dict):\n",
        "        return \"-\"\n",
        "\n",
        "    metadata_table = \"<table border='1' style='border-collapse: collapse; width: 100%; font-size: 12px;'>\"\n",
        "    for key, value in metadata_dict.items():\n",
        "        metadata_table += f\"<tr><td><b>{key}</b></td><td>{value}</td></tr>\"\n",
        "    metadata_table += \"</table>\"\n",
        "\n",
        "    return metadata_table\n",
        "\n",
        "def parse_request_types(input_text):\n",
        "    \"\"\"Parses request types from user input in the format:\n",
        "       Adjustment (Fee Adjustment, Principal Adjustment, Interest Adjustment)\"\"\"\n",
        "\n",
        "    request_types = []\n",
        "    # Split input by new lines or semicolons for multiple entries\n",
        "    entries = re.split(r'\\n|;', input_text.strip())\n",
        "\n",
        "    for entry in entries:\n",
        "        entry = entry.strip()\n",
        "        if not entry:\n",
        "            continue\n",
        "\n",
        "        match = re.match(r\"^(.+?)\\s*\\((.*?)\\)$\", entry)\n",
        "        if match:\n",
        "            request_type = match.group(1).strip()\n",
        "            subtypes = [sub.strip() for sub in match.group(2).split(\",\")]\n",
        "            request_types.append({\"request_type\": request_type, \"sub_request_types\": subtypes})\n",
        "        else:\n",
        "            # If no subtypes provided, assume it's a standalone request type\n",
        "            request_types.append({\"request_type\": entry, \"sub_request_types\": []})\n",
        "\n",
        "    return request_types\n",
        "\n",
        "def process_email_directory(email_dir, additional_rules, request_types_text):\n",
        "    \"\"\"Processes email directory and returns classification details as an HTML table with a loading indicator.\"\"\"\n",
        "\n",
        "    if not os.path.exists(email_dir):\n",
        "        return \"<p style='color:red;'>‚ùå Directory does not exist!</p>\"\n",
        "\n",
        "    # Parse request types\n",
        "    parsed_request_types = parse_request_types(request_types_text)\n",
        "\n",
        "    # Display loading message\n",
        "    loading_message = \"<p style='color:blue; font-size: 16px;'>‚è≥ Processing emails... Please wait.</p>\"\n",
        "    yield loading_message  # Show loading text in UI\n",
        "\n",
        "    time.sleep(1)  # Simulating a short delay for better UX\n",
        "\n",
        "    # Call the actual function to classify emails\n",
        "    result_json = classify_emails_from_dir(email_dir, additional_rules, parsed_request_types)\n",
        "\n",
        "    # Convert JSON list into an HTML table\n",
        "    table_html = \"<table border='1' style='border-collapse: collapse; width: 100%;'>\"\n",
        "    table_html += \"<tr><th>S.No</th><th>Email File</th><th>Request Type</th><th>Sub Request Type</th><th>Duplicate?</th><th>Confidence</th><th>Reason</th><th>Metadata Fields</th></tr>\"\n",
        "\n",
        "    for index, entry in enumerate(result_json, start=1):\n",
        "        metadata_html = format_metadata_as_html(entry.get(\"metadata_fields\", {}))  # Subtable for metadata\n",
        "        row_html = f\"\"\"\n",
        "            <tr>\n",
        "                <td>{index}</td>\n",
        "                <td>{entry.get(\"eml_file_name\", \"\")}</td>\n",
        "                <td>{entry.get(\"request_type\", \"-\")}</td>\n",
        "                <td>{entry.get(\"sub_request_type\", \"-\")}</td>\n",
        "                <td>{\"‚úÖ\" if entry.get(\"duplicate_flag\") else \"‚ùå\"}</td>\n",
        "                <td>{f\"{entry.get('confidence_score'):.2f}\" if entry.get(\"confidence_score\") else \"-\"}</td>\n",
        "                <td>{entry.get(\"reason\", \"-\")}</td>\n",
        "                <td>{metadata_html}</td>\n",
        "            </tr>\n",
        "        \"\"\"\n",
        "        table_html += row_html\n",
        "\n",
        "    table_html += \"</table>\"\n",
        "\n",
        "    yield table_html  # Update with final results\n",
        "\n",
        "# Gradio UI Setup\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üì© AI-Powered Email Classification & Metadata Extraction\")\n",
        "    gr.Markdown(\"### Enter Email Directory Path and Provide Additional Classification Rules\")\n",
        "\n",
        "    email_dir_input = gr.Textbox(label=\"Email Directory Path\", placeholder=\"Enter the path to email directory\")\n",
        "    additional_rules_input = gr.Textbox(label=\"Additional Classification Rules\", placeholder=\"Enter any additional rules for classification (optional)\")\n",
        "\n",
        "    request_types_input = gr.Textbox(\n",
        "        label=\"Request Types & Subtypes(Format: RequestType (SubRequestType1, SubRequestType2))\",\n",
        "        placeholder=\"Enter request types and subtypes in the specified format, one per line\",\n",
        "        lines=4\n",
        "    )\n",
        "\n",
        "    classify_button = gr.Button(\"Classify Emails\")\n",
        "    output_html = gr.HTML()\n",
        "\n",
        "    classify_button.click(\n",
        "        process_email_directory,\n",
        "        inputs=[email_dir_input, additional_rules_input, request_types_input],\n",
        "        outputs=output_html\n",
        "    )\n",
        "\n",
        "# Launch the Gradio Interface\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWb7irgrswg7"
      },
      "source": [
        "## Only for Testing - use the below code for cleaning up the collection from vector db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "CfNBvYfm9ONC"
      },
      "outputs": [],
      "source": [
        "#chroma_client = chromadb.PersistentClient(path=\"email_vectors_db\")\n",
        "#chroma_client.delete_collection(name='emails')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}